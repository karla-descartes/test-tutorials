{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "from datetime import datetime\n",
    "from subprocess import check_output\n",
    "import subprocess \n",
    "import json\n",
    "import pickle\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = subprocess.call('mkdir temp', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'Copying gs://dl-fires/inciweb-data/conus_fires_20180517-18UTC.txt...\\n/ [0 files][    0.0 B/  1.0 KiB]                                                \\r/ [1 files][  1.0 KiB/  1.0 KiB]                                                \\r\\nOperation completed over 1 objects/1.0 KiB.                                      \\n')\n"
     ]
    }
   ],
   "source": [
    "args = ['gsutil cp gs://dl-fires/inciweb-data/conus_fires_20180517-18UTC.txt temp/']\n",
    "p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "print p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_over_file(string):\n",
    "    counter = 0\n",
    "    for line in iter(string.splitlines()):\n",
    "        if counter == 0:\n",
    "            counter +=1\n",
    "        else: \n",
    "            initiate_fire_instance(line)\n",
    "            counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be refactored to include a class \n",
    "def initiate_fire_instance(fire_string): \n",
    "    fire_arr = fire_string.split()\n",
    "    name_list = fire_arr[:-4]\n",
    "    name = \" \".join(name_list)\n",
    "    fire_id = fire_arr[-4]\n",
    "    lat = float(fire_arr[-3])\n",
    "    lon = float(fire_arr[-2])\n",
    "    coords=[lat,lon]\n",
    "    acres = fire_arr[-1]\n",
    "    check_fire_status(fire_id, name, coords, acres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 'Copying gs://dl-fires/inciweb-data/conus_fires_20180518-18UTC.txt...\\n/ [0 files][    0.0 B/  1.1 KiB]                                                \\r/ [1 files][  1.1 KiB/  1.1 KiB]                                                \\r\\nOperation completed over 1 objects/1.1 KiB.                                      \\n')\n"
     ]
    }
   ],
   "source": [
    "# CURRENT RUN SCRIPT, though depends on the above being run first \n",
    "file_contents = read_latest_conus_file()\n",
    "iterate_over_file(file_string_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if fire instance exists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fire_status(fire_id, name, coordinates, acres):\n",
    "    fires = get_fire_instances() \n",
    "    if fire_id in fires:\n",
    "        last_checked =  fires[fire_id]['last_checked']\n",
    "        existing_fire(name, fire_id, coordinates, last_checked)\n",
    "    else:\n",
    "        print \"New fire\"\n",
    "        new_fire_instance(fire_id, name, coordinates, acres)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in latest Inciweb report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_latest_conus_file():\n",
    "    # List all files \n",
    "    args = ['gsutil ls gs://dl-fires/inciweb-data/']\n",
    "    p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    inciweb_data_files = p.communicate()[0]\n",
    " \n",
    "    # Isolate latest report  \n",
    "    latest_entry = inciweb_data_files.split('\\ngs://dl-fires/inciweb-data/')[-1]\n",
    "    conus_file = latest_entry.replace('\\n', '')\n",
    "    \n",
    "    # Download and open the latest report     \n",
    "    args = ['gsutil cp gs://dl-fires/inciweb-data/'+ conus_file +' temp/']\n",
    "    p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print p.communicate()\n",
    "    txt = open('temp/'+ conus_file)\n",
    "    file_string_contents = txt.read()\n",
    "    return file_string_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in fire instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fire_instances(): \n",
    "    with open('temp/fires.pickle', 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic for existing fire instance or new fire instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_fire_instance(fire_id, name, coordinates, acres): \n",
    "    five_days_ago = str(datetime.today() + timedelta(days=-5))\n",
    "    find_imagery(name, five_days_ago ,coordinates, fire_id) \n",
    "    \n",
    "    # Make bucket for imagery \n",
    "    'gs://dl-fires/imagery'+ fire_id\n",
    "    with open('temp/fires.pickle', 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "        b[fire_id] = {\n",
    "            'name': 'Mallard Fire',\n",
    "            'date_entered': datetime.today().isoformat()\n",
    "        }\n",
    "        \n",
    "    with open('temp/fires.pickle', 'wb') as handle:\n",
    "        pickle.dump(b, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def existing_fire(name, fire_id, coordinates, last_checked):\n",
    "#     bucket = 'gs://dl-fires/imagery/'+ fire_id\n",
    "    find_imagery(name, last_checked ,coordinates, fire_id ) \n",
    "    with open('temp/fires.pickle', 'rb') as handle:\n",
    "        b = pickle.load(handle)\n",
    "        b[fire_id]['last_checked'] = datetime.today().isoformat()\n",
    "        \n",
    "    with open('temp/fires.pickle', 'wb') as handle:\n",
    "        pickle.dump(b, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tile(coords): \n",
    "    # to get the tile centered around your lat/lon, give it a tilesize of 1 and a pad of the half-width of your desired image (in meters)\n",
    "    print coords[0]\n",
    "    print coords[1]\n",
    "    bounding_box = dl.raster.dltile_from_latlon(\n",
    "        lat=coords[0],\n",
    "        lon=coords[1], \n",
    "        resolution=30, \n",
    "        tilesize=2, \n",
    "        pad=600)\n",
    "\n",
    "    return bounding_box\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_products(date, geometry):\n",
    "    print(date)\n",
    "    from pprint import pprint \n",
    "    pprint(geometry['geometry']['coordinates'])\n",
    "    images = dl.metadata.search(\n",
    "        ['landsat:LC08:01:RT:TOAR', 'sentinel-2:L1C'],\n",
    "        geom= geometry, \n",
    "        start_datetime=date, \n",
    "        end_datetime= datetime.today().isoformat()\n",
    "        )\n",
    "    pprint(\"The number of total images found is {}.\".format(len(images['features'])))\n",
    "    return [image['id'] for image in images['features']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_imagery(ids, geometry, fire_id):\n",
    "    for image_id in ids: \n",
    "        print image_id\n",
    "        dl.raster.raster(\n",
    "                        image_id,\n",
    "                        bands=['swir2', 'swir1', 'nir', 'alpha'],\n",
    "                        scales=[[0,4000], [0, 4000], [0, 4000], None],\n",
    "                        data_type='Byte',\n",
    "                        cutline=geometry,\n",
    "                        save= True,\n",
    "                        outfile_basename=\"temp/\"+image_id)\n",
    "\n",
    "        # Sync images to associated bucket\n",
    "        args = ['gsutil cp  temp/'+image_id+ '.tif gs://dl-fires/imagery/'+fire_id+'/']\n",
    "        p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        print p.communicate()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_imagery(fire_name, date, coords, fire_id, footprint=None):\n",
    "    # Where name is a str, coords is an array of [lat,long], and footprint is an optional geometry\n",
    "    # if footprint:\n",
    "        # image_ids = search_products(date,footprint)\n",
    "        # download_imagery(image_ids, footprint)\n",
    "    # else:\n",
    "    dl_tile = make_tile(coords)\n",
    "    image_ids = search_products(date, dl_tile)\n",
    "    download_imagery(image_ids, dl_tile, fire_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = {\n",
    "    'id:5790':{\n",
    "        'name': 'Mallard Fire',\n",
    "        'date_entered': '2018-05-10',\n",
    "        'last_checked': '2018-05-15'\n",
    "    },\n",
    "    'id:5795':{\n",
    "        'name': 'Pinery Fire',\n",
    "        'date_entered': '2018-05-10',\n",
    "        'last_checked': '2018-05-15'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('temp/fires.pickle', 'wb') as handle:\n",
    "    pickle.dump(fires, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('temp/fires.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ['gsutil ls gs://dl-fires/imagery']\n",
    "p = subprocess.Popen(args, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "buckets= p.communicate()[0]\n",
    "buckets = buckets.split('\\ngs://dl-fires/imagery/')\n",
    "buckets = [bucket.replace('/', '') for bucket in buckets]\n",
    "buckets = [bucket.replace('\\n', '') for bucket in buckets]\n",
    "buckets = buckets[1:]\n",
    "buckets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-env",
   "language": "python",
   "name": "dl-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
